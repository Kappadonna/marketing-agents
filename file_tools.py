"""Virtual file system tools for agent state management.

VERSION 2.1 - CRITICAL FIX:
- Added protection against overwriting tool-generated files
- Prevents agents from manually overwriting images/charts with placeholders
- Enhanced validation and error messages
"""

from typing import Annotated
import sys

from langchain_core.messages import ToolMessage
from langchain_core.tools import InjectedToolCallId, tool
from langgraph.prebuilt import InjectedState
from langgraph.types import Command

from prompts import (
    LS_DESCRIPTION,
    READ_FILE_DESCRIPTION,
    WRITE_FILE_DESCRIPTION,
)
from state import MarketingCampaignState


@tool(description=LS_DESCRIPTION)
def ls(state: Annotated[MarketingCampaignState, InjectedState]) -> list[str]:
    """List all files in the virtual filesystem."""
    return list(state.get("files", {}).keys())


@tool(description=READ_FILE_DESCRIPTION, parse_docstring=True)
def read_file(
    file_path: str,
    state: Annotated[MarketingCampaignState, InjectedState],
    offset: int = 0,
    limit: int = 2000,
) -> str:
    """Read file content from virtual filesystem with optional offset and limit.

    Args:
        file_path: Path to the file to read
        state: Agent state containing virtual filesystem (injected in tool node)
        offset: Line number to start reading from (default: 0)
        limit: Maximum number of lines to read (default: 2000)

    Returns:
        Formatted file content with line numbers, or error message if file not found
    """
    files = state.get("files", {})
    if file_path not in files:
        return f"Error: File '{file_path}' not found"

    content = files[file_path]
    if not content:
        return "System reminder: File exists but has empty contents"

    lines = content.splitlines()
    start_idx = offset
    end_idx = min(start_idx + limit, len(lines))

    if start_idx >= len(lines):
        return f"Error: Line offset {offset} exceeds file length ({len(lines)} lines)"

    result_lines = []
    for i in range(start_idx, end_idx):
        line_content = lines[i][:2000]
        result_lines.append(f"{i + 1:6d}\t{line_content}")

    return "\n".join(result_lines)


@tool(description=WRITE_FILE_DESCRIPTION, parse_docstring=True)
def write_file(
    file_path: str,
    content: str,
    state: Annotated[MarketingCampaignState, InjectedState],
    tool_call_id: Annotated[str, InjectedToolCallId],
) -> Command:
    """Write content to a file in the virtual filesystem with validation.

    VERSION 2.1 CRITICAL ENHANCEMENT:
    - Prevents overwriting tool-generated files (images, charts)
    - This fixes the bug where agents overwrite complete files with placeholders
    
    Protected files are those created by:
    - generate_marketing_image() ‚Üí post_image_v[N].md, post_image_data_v[N].txt
    - create_metrics_chart() ‚Üí metrics_chart_v[N].md, metrics_chart_data_v[N].txt

    Args:
        file_path: Path where the file should be created/updated
        content: Content to write to the file
        state: Agent state (injected)
        tool_call_id: Tool call identifier (injected)

    Returns:
        Command to update agent state or error if file is protected
    """
    
    # ===================================================================
    # CRITICAL: PROTECTION AGAINST OVERWRITING TOOL-GENERATED FILES
    # ===================================================================
    
    # Define patterns for tool-generated files
    TOOL_GENERATED_PATTERNS = [
        r'post_image_v\d+\.md$',         # Image metadata
        r'post_image_data_v\d+\.txt$',   # Image data
        r'metrics_chart_v\d+\.md$',      # Chart metadata
        r'metrics_chart_data_v\d+\.txt$', # Chart data
        r'iteration_comparison_chart\.md$',     # Comparison chart metadata
        r'iteration_comparison_chart_data\.txt$' # Comparison chart data
    ]
    
    # Check if filename matches any protected pattern
    import re
    is_tool_file_by_pattern = any(re.search(pattern, file_path) for pattern in TOOL_GENERATED_PATTERNS)
    
    # Also check the tool_generated_files set
    tool_generated_files = state.get('tool_generated_files', set())
    is_tool_file_by_set = file_path in tool_generated_files
    
    # Protect if either condition is true
    if is_tool_file_by_pattern or is_tool_file_by_set:
        current_size = len(state.get('files', {}).get(file_path, ''))
        attempted_size = len(content)
        
        protection_reason = []
        if is_tool_file_by_pattern:
            protection_reason.append("filename matches tool-generated pattern")
        if is_tool_file_by_set:
            protection_reason.append("file is in protected set")
        
        error_msg = f"""üõë PROTECTION ACTIVATED: Cannot overwrite {file_path}

**Reason**: This file was generated by a tool and is protected from manual overwrite.
**Protection triggered by**: {' AND '.join(protection_reason)}

**Current Status**:
- File: {file_path}
- Generated by: Tool (image/chart generation)
- Current size: {current_size:,} chars ‚úÖ COMPLETE
- Attempted overwrite: {attempted_size:,} chars ‚ö†Ô∏è LIKELY PLACEHOLDER

**What Happened**:
You called a tool (e.g., generate_marketing_image or create_metrics_chart) 
which created this file automatically and completely. Now you're trying to 
overwrite it with write_file(), which would DESTROY the complete data!

**What To Do**:
‚úÖ DO: Leave this file alone - it's already complete
‚úÖ DO: If you need to recreate it, call the original tool again
‚ùå DON'T: Call write_file() on tool-generated files

**Protected Files in This Session**:
{chr(10).join(f'  üîí {f}' for f in sorted(tool_generated_files))}

**Action**: File write BLOCKED. Continue with other tasks.
"""
        print(f"\n‚ö†Ô∏è OVERWRITE BLOCKED: {file_path}")
        print(f"   Current: {current_size:,} chars | Attempted: {attempted_size:,} chars\n")
        
        return Command(
            update={
                "messages": [ToolMessage(error_msg, tool_call_id=tool_call_id)]
            }
        )
    
    # ===================================================================
    # VALIDATION CHECKS (existing v2.0 code)
    # ===================================================================
    if not content:
        error_msg = f"‚ùå Error: Cannot write empty content to {file_path}"
        return Command(
            update={
                "messages": [ToolMessage(error_msg, tool_call_id=tool_call_id)]
            }
        )
    
    # Check content size
    content_size = sys.getsizeof(content)
    content_lines = len(content.splitlines())
    content_chars = len(content)
    
    # Warning for suspiciously small files
    if content_chars < 100:
        warning = f"‚ö†Ô∏è Warning: File {file_path} is very small ({content_chars} chars)"
        print(warning)
    
    # Perform the write
    files = state.get("files", {})
    files[file_path] = content
    
    # Verify write was successful
    if files.get(file_path) != content:
        error_msg = f"‚ùå Error: Failed to write {file_path} - verification failed"
        return Command(
            update={
                "messages": [ToolMessage(error_msg, tool_call_id=tool_call_id)]
            }
        )
    
    # Success message with stats
    success_msg = f"""‚úÖ Updated file: {file_path}
üìä Size: {content_chars:,} chars | {content_lines} lines | {content_size:,} bytes
‚úì Write verified"""
    
    return Command(
        update={
            "files": files,
            "messages": [
                ToolMessage(success_msg, tool_call_id=tool_call_id)
            ],
        }
    )


@tool(parse_docstring=True)
def verify_iteration_complete(
    iteration: int,
    state: Annotated[MarketingCampaignState, InjectedState],
) -> str:
    """Verify all required files exist AND have valid content for a campaign iteration.
    
    This tool performs a comprehensive check that ALL mandatory files have been 
    created for an iteration. It returns a detailed status report showing which 
    files exist and which are missing, along with actionable recommendations.
    
    Use this tool at checkpoints to ensure an iteration is complete before 
    proceeding to the next phase or iteration.
    
    Args:
        iteration: The iteration number to verify (e.g., 1, 2, 3)
        state: Agent state containing virtual filesystem (automatically injected)
    
    Returns:
        Comprehensive report showing file verification status, content validation,
        and actionable recommendations
        
    Example:
        verify_iteration_complete(iteration=2)
        # Returns detailed report of all files for iteration 2 with content checks
    """
    # Define all required files for a complete iteration
    required_files = {
        "Strategy Report": f"strategy_report_v{iteration}.md",
        "Post Content": f"post_content_v{iteration}.md",
        "Post Image Metadata": f"post_image_v{iteration}.md",
        "Post Image Data": f"post_image_data_v{iteration}.txt",
        "Analytics Report": f"analytics_report_v{iteration}.md",
        "Metrics Chart Metadata": f"metrics_chart_v{iteration}.md",
        "Metrics Chart Data": f"metrics_chart_data_v{iteration}.txt",
    }
    
    # Expected minimum sizes (in characters) for each file type
    min_sizes = {
        "Strategy Report": 1000,
        "Post Content": 300,
        "Post Image Metadata": 200,
        "Post Image Data": 50000,
        "Analytics Report": 800,
        "Metrics Chart Metadata": 200,
        "Metrics Chart Data": 10000,
    }
    
    files = state.get("files", {})
    
    # Detailed validation results
    validation_results = {}
    missing = []
    present = []
    content_issues = []
    
    for category, filename in required_files.items():
        exists = filename in files
        
        if not exists:
            validation_results[category] = {
                "exists": False,
                "valid_content": False,
                "size": 0,
                "issue": "File missing"
            }
            missing.append(f"‚ùå {category}: {filename}")
        else:
            # File exists - now check content
            content = files[filename]
            content_size = len(content)
            min_size = min_sizes.get(category, 100)
            
            is_valid = content_size >= min_size
            
            # Special validation for base64 files
            if "Data" in category:
                content_stripped = content.strip()
                # Check for placeholder text
                if "[Base64" in content or "placeholder" in content.lower():
                    is_valid = False
                    issue = "Contains placeholder text instead of real data"
                # Base64 should be mostly alphanumeric
                elif len(content_stripped) < min_size:
                    is_valid = False
                    issue = f"Too small: {content_size}/{min_size} chars"
                else:
                    non_base64_chars = sum(1 for c in content_stripped if c not in 
                                          'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\n\r# ')
                    if non_base64_chars > len(content_stripped) * 0.05:
                        is_valid = False
                        issue = f"Invalid base64 data ({non_base64_chars} bad chars)"
                    else:
                        issue = None
            else:
                issue = None
            
            validation_results[category] = {
                "exists": True,
                "valid_content": is_valid,
                "size": content_size,
                "issue": issue or (f"Too small: {content_size}/{min_size} chars" if not is_valid else None)
            }
            
            if is_valid:
                present.append(f"‚úÖ {category}: {filename} ({content_size:,} chars)")
            else:
                content_issues.append(f"‚ö†Ô∏è {category}: {filename} - {validation_results[category]['issue']}")
    
    # Build comprehensive report
    total = len(required_files)
    complete_count = len([r for r in validation_results.values() if r["valid_content"]])
    missing_count = len(missing)
    issue_count = len(content_issues)
    
    is_complete = missing_count == 0 and issue_count == 0
    
    separator = "=" * 70
    report = f"""
{separator}
ITERATION {iteration} COMPREHENSIVE FILE VERIFICATION REPORT
{separator}

Overall Status: {'‚úÖ COMPLETE & VALIDATED' if is_complete else f'‚ùå INCOMPLETE ({complete_count}/{total} files valid)'}

FILES WITH VALID CONTENT: {complete_count}/{total}
MISSING FILES: {missing_count}
CONTENT ISSUES: {issue_count}

{separator}
DETAILED FILE CHECKLIST:
{separator}
"""
    
    # List all files with their detailed status
    for category, filename in required_files.items():
        result = validation_results[category]
        if result["valid_content"]:
            symbol = "‚úÖ"
            status = f"Valid ({result['size']:,} chars)"
        elif not result["exists"]:
            symbol = "‚ùå"
            status = "MISSING"
        else:
            symbol = "‚ö†Ô∏è"
            status = result["issue"]
        
        report += f"\n{symbol} {category}: {filename}"
        report += f"\n   Status: {status}\n"
    
    if missing or content_issues:
        report += f"\n{separator}"
        report += f"\n‚ö†Ô∏è ISSUES DETECTED"
        report += f"\n{separator}"
        
        if missing:
            report += f"\n\nüî¥ MISSING FILES ({missing_count}):"
            for item in missing:
                report += f"\n   {item}"
        
        if content_issues:
            report += f"\n\nüü° CONTENT ISSUES ({issue_count}):"
            for item in content_issues:
                report += f"\n   {item}"
        
        report += "\n\n‚ö° ACTION REQUIRED:"
        report += "\n" + separator
        
        # Provide specific recommendations
        strategy_issues = any("strategy" in str(v).lower() for v in [missing, content_issues])
        content_issues_present = any("content" in str(v).lower() or "image" in str(v).lower() 
                                     for v in [missing, content_issues])
        analytics_issues = any("analytics" in str(v).lower() or "chart" in str(v).lower() 
                              for v in [missing, content_issues])
        
        if strategy_issues:
            report += "\n‚Üí Re-delegate to 'strategy-planner' with explicit instruction"
        if content_issues_present:
            report += "\n‚Üí Re-delegate to 'content-creator' with explicit instruction"
            report += "\n   CRITICAL: Must call generate_marketing_image() - don't manually write image files"
        if analytics_issues:
            report += "\n‚Üí Re-delegate to 'analytics-agent' with explicit instruction"
            report += "\n   CRITICAL: Must call create_metrics_chart() - don't manually write chart files"
        
        report += "\n\nüõë DO NOT PROCEED to next iteration until ALL files are present AND valid."
    
    else:
        report += f"\n{separator}"
        report += f"\n‚úÖ ALL FILES PRESENT AND VALIDATED"
        report += f"\n{separator}"
        report += f"\nIteration {iteration} is COMPLETE with valid content."
    
    report += f"\n\n{separator}\n"
    
    return report


# Export all tools
__all__ = ['ls', 'read_file', 'write_file', 'verify_iteration_complete']